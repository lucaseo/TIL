{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b91a74ba-85f4-486e-b5f9-d0898f0626bf",
    "_uuid": "6ac53f18b4f4ec0fc44348cedb5d1c319fa127c0"
   },
   "source": [
    "Welcome to day 1 of the 5-Day Data Challenge! Today, we're going to be looking at how to deal with missing values. \n",
    "\n",
    "Here's what we're going to do today:\n",
    "\n",
    "* [Take a first look at the data](#Take-a-first-look-at-the-data)\n",
    "* [See how many missing data points we have](#See-how-many-missing-data-points-we-have)\n",
    "* [Figure out why the data is missing](#Figure-out-why-the-data-is-missing)\n",
    "* [Drop missing values](#Drop-missing-values)\n",
    "* [Filling in missing values](#Filling-in-missing-values)\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5cd5061f-ae30-4837-a53b-690ffd5c5830",
    "_uuid": "9d82bf13584b8e682962fbb96131f2447d741679"
   },
   "source": [
    "# Take a first look at the data\n",
    "______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "135a7804-b5f5-40aa-8657-4a15774e3666",
    "_uuid": "835cbe0834b935fb0fd40c75b9c39454836f4d5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (25,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (22,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read in data we'll use\n",
    "nfl_data = pd.read_csv(\"../../../../00_dataset_archive/kaggle-5-day-data-cleaning-challenge/NFL Play by Play 2009-2017 (v4).csv\")\n",
    "sf_permits = pd.read_csv(\"../../../../00_dataset_archive/kaggle-5-day-data-cleaning-challenge/Building_Permits.csv\")\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Permit Number</th>\n",
       "      <th>Permit Type</th>\n",
       "      <th>Permit Type Definition</th>\n",
       "      <th>Permit Creation Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>Lot</th>\n",
       "      <th>Street Number</th>\n",
       "      <th>Street Number Suffix</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Street Suffix</th>\n",
       "      <th>...</th>\n",
       "      <th>Existing Construction Type</th>\n",
       "      <th>Existing Construction Type Description</th>\n",
       "      <th>Proposed Construction Type</th>\n",
       "      <th>Proposed Construction Type Description</th>\n",
       "      <th>Site Permit</th>\n",
       "      <th>Supervisor District</th>\n",
       "      <th>Neighborhoods - Analysis Boundaries</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Location</th>\n",
       "      <th>Record ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201505065519</td>\n",
       "      <td>4</td>\n",
       "      <td>sign - erect</td>\n",
       "      <td>05/06/2015</td>\n",
       "      <td>0326</td>\n",
       "      <td>023</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ellis</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>constr type 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>94102.0</td>\n",
       "      <td>(37.785719256680785, -122.40852313194863)</td>\n",
       "      <td>1380611233945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201604195146</td>\n",
       "      <td>4</td>\n",
       "      <td>sign - erect</td>\n",
       "      <td>04/19/2016</td>\n",
       "      <td>0306</td>\n",
       "      <td>007</td>\n",
       "      <td>440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geary</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>constr type 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>94102.0</td>\n",
       "      <td>(37.78733980600732, -122.41063199757738)</td>\n",
       "      <td>1420164406718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201605278609</td>\n",
       "      <td>3</td>\n",
       "      <td>additions alterations or repairs</td>\n",
       "      <td>05/27/2016</td>\n",
       "      <td>0595</td>\n",
       "      <td>203</td>\n",
       "      <td>1647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>Av</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>constr type 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>constr type 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Russian Hill</td>\n",
       "      <td>94109.0</td>\n",
       "      <td>(37.7946573324287, -122.42232562979227)</td>\n",
       "      <td>1424856504716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201611072166</td>\n",
       "      <td>8</td>\n",
       "      <td>otc alterations permit</td>\n",
       "      <td>11/07/2016</td>\n",
       "      <td>0156</td>\n",
       "      <td>011</td>\n",
       "      <td>1230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>Av</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Nob Hill</td>\n",
       "      <td>94109.0</td>\n",
       "      <td>(37.79595867909168, -122.41557405519474)</td>\n",
       "      <td>1443574295566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201611283529</td>\n",
       "      <td>6</td>\n",
       "      <td>demolitions</td>\n",
       "      <td>11/28/2016</td>\n",
       "      <td>0342</td>\n",
       "      <td>001</td>\n",
       "      <td>950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Market</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>constr type 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>94102.0</td>\n",
       "      <td>(37.78315261897309, -122.40950883997789)</td>\n",
       "      <td>144548169992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Permit Number  Permit Type            Permit Type Definition  \\\n",
       "0  201505065519            4                      sign - erect   \n",
       "1  201604195146            4                      sign - erect   \n",
       "2  201605278609            3  additions alterations or repairs   \n",
       "3  201611072166            8            otc alterations permit   \n",
       "4  201611283529            6                       demolitions   \n",
       "\n",
       "  Permit Creation Date Block  Lot  Street Number Street Number Suffix  \\\n",
       "0           05/06/2015  0326  023            140                  NaN   \n",
       "1           04/19/2016  0306  007            440                  NaN   \n",
       "2           05/27/2016  0595  203           1647                  NaN   \n",
       "3           11/07/2016  0156  011           1230                  NaN   \n",
       "4           11/28/2016  0342  001            950                  NaN   \n",
       "\n",
       "  Street Name Street Suffix      ...        Existing Construction Type  \\\n",
       "0       Ellis            St      ...                               3.0   \n",
       "1       Geary            St      ...                               3.0   \n",
       "2     Pacific            Av      ...                               1.0   \n",
       "3     Pacific            Av      ...                               5.0   \n",
       "4      Market            St      ...                               3.0   \n",
       "\n",
       "  Existing Construction Type Description Proposed Construction Type  \\\n",
       "0                          constr type 3                        NaN   \n",
       "1                          constr type 3                        NaN   \n",
       "2                          constr type 1                        1.0   \n",
       "3                         wood frame (5)                        5.0   \n",
       "4                          constr type 3                        NaN   \n",
       "\n",
       "  Proposed Construction Type Description Site Permit Supervisor District  \\\n",
       "0                                    NaN         NaN                 3.0   \n",
       "1                                    NaN         NaN                 3.0   \n",
       "2                          constr type 1         NaN                 3.0   \n",
       "3                         wood frame (5)         NaN                 3.0   \n",
       "4                                    NaN         NaN                 6.0   \n",
       "\n",
       "  Neighborhoods - Analysis Boundaries  Zipcode  \\\n",
       "0                          Tenderloin  94102.0   \n",
       "1                          Tenderloin  94102.0   \n",
       "2                        Russian Hill  94109.0   \n",
       "3                            Nob Hill  94109.0   \n",
       "4                          Tenderloin  94102.0   \n",
       "\n",
       "                                    Location      Record ID  \n",
       "0  (37.785719256680785, -122.40852313194863)  1380611233945  \n",
       "1   (37.78733980600732, -122.41063199757738)  1420164406718  \n",
       "2    (37.7946573324287, -122.42232562979227)  1424856504716  \n",
       "3   (37.79595867909168, -122.41557405519474)  1443574295566  \n",
       "4   (37.78315261897309, -122.40950883997789)   144548169992  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_permits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09b58d03-d34d-497a-b298-12a0ae962e3d",
    "_uuid": "53c84bf86149ac41b237633a1a79d6130d6a2cd4"
   },
   "source": [
    "The first thing I do when I get a new dataset is take a look at some of it. This lets me see that it all read in correctly and get an idea of what's going on with the data. In this case, I'm looking to see if I see any missing values, which will be reprsented with `NaN` or `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GameID</th>\n",
       "      <th>Drive</th>\n",
       "      <th>qtr</th>\n",
       "      <th>down</th>\n",
       "      <th>time</th>\n",
       "      <th>TimeUnder</th>\n",
       "      <th>TimeSecs</th>\n",
       "      <th>PlayTimeDiff</th>\n",
       "      <th>SideofField</th>\n",
       "      <th>...</th>\n",
       "      <th>yacEPA</th>\n",
       "      <th>Home_WP_pre</th>\n",
       "      <th>Away_WP_pre</th>\n",
       "      <th>Home_WP_post</th>\n",
       "      <th>Away_WP_post</th>\n",
       "      <th>Win_Prob</th>\n",
       "      <th>WPA</th>\n",
       "      <th>airWPA</th>\n",
       "      <th>yacWPA</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244485</th>\n",
       "      <td>2014-10-26</td>\n",
       "      <td>2014102607</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>00:39</td>\n",
       "      <td>1</td>\n",
       "      <td>939.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>TB</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240299</td>\n",
       "      <td>0.225647</td>\n",
       "      <td>0.774353</td>\n",
       "      <td>0.245582</td>\n",
       "      <td>0.754418</td>\n",
       "      <td>0.225647</td>\n",
       "      <td>0.019935</td>\n",
       "      <td>-0.018156</td>\n",
       "      <td>0.038091</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115340</th>\n",
       "      <td>2011-11-20</td>\n",
       "      <td>2011112000</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>06:47</td>\n",
       "      <td>7</td>\n",
       "      <td>407.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>OAK</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.056036</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.042963</td>\n",
       "      <td>0.957037</td>\n",
       "      <td>0.943964</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68357</th>\n",
       "      <td>2010-11-14</td>\n",
       "      <td>2010111401</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:23</td>\n",
       "      <td>1</td>\n",
       "      <td>1823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CLE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.365307</td>\n",
       "      <td>0.634693</td>\n",
       "      <td>0.384697</td>\n",
       "      <td>0.615303</td>\n",
       "      <td>0.634693</td>\n",
       "      <td>-0.019390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368377</th>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>2017092405</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>08:48</td>\n",
       "      <td>9</td>\n",
       "      <td>528.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>CLE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.075660</td>\n",
       "      <td>0.935995</td>\n",
       "      <td>0.064005</td>\n",
       "      <td>0.921231</td>\n",
       "      <td>0.078769</td>\n",
       "      <td>0.064005</td>\n",
       "      <td>0.014764</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384684</th>\n",
       "      <td>2017-11-05</td>\n",
       "      <td>2017110505</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>09:15</td>\n",
       "      <td>10</td>\n",
       "      <td>2355.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DEN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.928474</td>\n",
       "      <td>0.071526</td>\n",
       "      <td>0.934641</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.071526</td>\n",
       "      <td>-0.006166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date      GameID  Drive  qtr  down   time  TimeUnder  TimeSecs  \\\n",
       "244485  2014-10-26  2014102607     18    3   1.0  00:39          1     939.0   \n",
       "115340  2011-11-20  2011112000     22    4   1.0  06:47          7     407.0   \n",
       "68357   2010-11-14  2010111401      8    2   NaN  00:23          1    1823.0   \n",
       "368377  2017-09-24  2017092405     24    4   1.0  08:48          9     528.0   \n",
       "384684  2017-11-05  2017110505     11    2   1.0  09:15         10    2355.0   \n",
       "\n",
       "        PlayTimeDiff SideofField   ...      yacEPA  Home_WP_pre  Away_WP_pre  \\\n",
       "244485          12.0          TB   ...    1.240299     0.225647     0.774353   \n",
       "115340          44.0         OAK   ...         NaN     0.056036     0.943964   \n",
       "68357            0.0         CLE   ...         NaN     0.365307     0.634693   \n",
       "368377           8.0         CLE   ...    1.075660     0.935995     0.064005   \n",
       "384684           0.0         DEN   ...         NaN     0.928474     0.071526   \n",
       "\n",
       "        Home_WP_post  Away_WP_post  Win_Prob       WPA    airWPA    yacWPA  \\\n",
       "244485      0.245582      0.754418  0.225647  0.019935 -0.018156  0.038091   \n",
       "115340      0.042963      0.957037  0.943964  0.013073       NaN       NaN   \n",
       "68357       0.384697      0.615303  0.634693 -0.019390       NaN       NaN   \n",
       "368377      0.921231      0.078769  0.064005  0.014764  0.003866  0.010899   \n",
       "384684      0.934641      0.065359  0.071526 -0.006166       NaN       NaN   \n",
       "\n",
       "        Season  \n",
       "244485    2014  \n",
       "115340    2011  \n",
       "68357     2010  \n",
       "368377    2017  \n",
       "384684    2017  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at a few rows of the nfl_data file. I can see a handful of missing data already!\n",
    "nfl_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "604ac3a4-b1d9-4264-b312-4bbeecdeec00",
    "_uuid": "03ce3b4afe87d98f777172c2c7be066a66a0b237"
   },
   "source": [
    "Yep, it looks like there's some missing values. What about in the sf_permits dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "8dca377c-95be-40ec-87dc-61a8fca750e2",
    "_uuid": "e389495bb2e5d27ab632d5f3648ca1f912c94706"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Permit Number</th>\n",
       "      <th>Permit Type</th>\n",
       "      <th>Permit Type Definition</th>\n",
       "      <th>Permit Creation Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>Lot</th>\n",
       "      <th>Street Number</th>\n",
       "      <th>Street Number Suffix</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Street Suffix</th>\n",
       "      <th>...</th>\n",
       "      <th>Existing Construction Type</th>\n",
       "      <th>Existing Construction Type Description</th>\n",
       "      <th>Proposed Construction Type</th>\n",
       "      <th>Proposed Construction Type Description</th>\n",
       "      <th>Site Permit</th>\n",
       "      <th>Supervisor District</th>\n",
       "      <th>Neighborhoods - Analysis Boundaries</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Location</th>\n",
       "      <th>Record ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60635</th>\n",
       "      <td>201409105988</td>\n",
       "      <td>3</td>\n",
       "      <td>additions alterations or repairs</td>\n",
       "      <td>09/10/2014</td>\n",
       "      <td>0479</td>\n",
       "      <td>027</td>\n",
       "      <td>1356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chestnut</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>Y</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Marina</td>\n",
       "      <td>94123.0</td>\n",
       "      <td>(37.802444119694016, -122.42570568145257)</td>\n",
       "      <td>1355098392583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110430</th>\n",
       "      <td>201601046309</td>\n",
       "      <td>8</td>\n",
       "      <td>otc alterations permit</td>\n",
       "      <td>01/04/2016</td>\n",
       "      <td>1276</td>\n",
       "      <td>001H</td>\n",
       "      <td>202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Grattan</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Haight Ashbury</td>\n",
       "      <td>94117.0</td>\n",
       "      <td>(37.7639230255061, -122.45133897567636)</td>\n",
       "      <td>1408159479509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165042</th>\n",
       "      <td>201707212672</td>\n",
       "      <td>3</td>\n",
       "      <td>additions alterations or repairs</td>\n",
       "      <td>07/21/2017</td>\n",
       "      <td>3622</td>\n",
       "      <td>004</td>\n",
       "      <td>818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Noe</td>\n",
       "      <td>St</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>Y</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Noe Valley</td>\n",
       "      <td>94114.0</td>\n",
       "      <td>(37.755878042652135, -122.43257973156736)</td>\n",
       "      <td>1471545162735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79200</th>\n",
       "      <td>201503171100</td>\n",
       "      <td>8</td>\n",
       "      <td>otc alterations permit</td>\n",
       "      <td>03/17/2015</td>\n",
       "      <td>1509</td>\n",
       "      <td>009</td>\n",
       "      <td>547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35th</td>\n",
       "      <td>Av</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Outer Richmond</td>\n",
       "      <td>94121.0</td>\n",
       "      <td>(37.778632168486645, -122.49570921682907)</td>\n",
       "      <td>1374631102139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76487</th>\n",
       "      <td>201502208860</td>\n",
       "      <td>8</td>\n",
       "      <td>otc alterations permit</td>\n",
       "      <td>02/20/2015</td>\n",
       "      <td>1923</td>\n",
       "      <td>023</td>\n",
       "      <td>1662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21st</td>\n",
       "      <td>Av</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wood frame (5)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sunset/Parkside</td>\n",
       "      <td>94122.0</td>\n",
       "      <td>(37.756722563984916, -122.47846371493331)</td>\n",
       "      <td>1371767120653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Permit Number  Permit Type            Permit Type Definition  \\\n",
       "60635   201409105988            3  additions alterations or repairs   \n",
       "110430  201601046309            8            otc alterations permit   \n",
       "165042  201707212672            3  additions alterations or repairs   \n",
       "79200   201503171100            8            otc alterations permit   \n",
       "76487   201502208860            8            otc alterations permit   \n",
       "\n",
       "       Permit Creation Date Block   Lot  Street Number Street Number Suffix  \\\n",
       "60635            09/10/2014  0479   027           1356                  NaN   \n",
       "110430           01/04/2016  1276  001H            202                  NaN   \n",
       "165042           07/21/2017  3622   004            818                  NaN   \n",
       "79200            03/17/2015  1509   009            547                  NaN   \n",
       "76487            02/20/2015  1923   023           1662                  NaN   \n",
       "\n",
       "       Street Name Street Suffix      ...        Existing Construction Type  \\\n",
       "60635     Chestnut            St      ...                               5.0   \n",
       "110430     Grattan            St      ...                               5.0   \n",
       "165042         Noe            St      ...                               5.0   \n",
       "79200         35th            Av      ...                               5.0   \n",
       "76487         21st            Av      ...                               5.0   \n",
       "\n",
       "       Existing Construction Type Description Proposed Construction Type  \\\n",
       "60635                          wood frame (5)                        5.0   \n",
       "110430                         wood frame (5)                        5.0   \n",
       "165042                         wood frame (5)                        5.0   \n",
       "79200                          wood frame (5)                        5.0   \n",
       "76487                          wood frame (5)                        5.0   \n",
       "\n",
       "       Proposed Construction Type Description Site Permit Supervisor District  \\\n",
       "60635                          wood frame (5)           Y                 2.0   \n",
       "110430                         wood frame (5)         NaN                 5.0   \n",
       "165042                         wood frame (5)           Y                 8.0   \n",
       "79200                          wood frame (5)         NaN                 1.0   \n",
       "76487                          wood frame (5)         NaN                 4.0   \n",
       "\n",
       "       Neighborhoods - Analysis Boundaries  Zipcode  \\\n",
       "60635                               Marina  94123.0   \n",
       "110430                      Haight Ashbury  94117.0   \n",
       "165042                          Noe Valley  94114.0   \n",
       "79200                       Outer Richmond  94121.0   \n",
       "76487                      Sunset/Parkside  94122.0   \n",
       "\n",
       "                                         Location      Record ID  \n",
       "60635   (37.802444119694016, -122.42570568145257)  1355098392583  \n",
       "110430    (37.7639230255061, -122.45133897567636)  1408159479509  \n",
       "165042  (37.755878042652135, -122.43257973156736)  1471545162735  \n",
       "79200   (37.778632168486645, -122.49570921682907)  1374631102139  \n",
       "76487   (37.756722563984916, -122.47846371493331)  1371767120653  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your turn! Look at a couple of rows from the sf_permits dataset. Do you notice any missing data?\n",
    "\n",
    "sf_permits.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "33656c2b-a74e-4b76-9af2-d7ecd518577b",
    "_uuid": "400b025f618cc76a39fec2537193f28ba1e49168"
   },
   "source": [
    "# See how many missing data points we have\n",
    "___\n",
    "\n",
    "Ok, now we know that we do have some missing values. Let's see how many we have in each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "a69ac02d-197b-487b-a38f-2f853d208eed",
    "_uuid": "6dc0e32180c4a3bba003e7886faf126d93affadf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                0\n",
       "GameID              0\n",
       "Drive               0\n",
       "qtr                 0\n",
       "down            61154\n",
       "time              224\n",
       "TimeUnder           0\n",
       "TimeSecs          224\n",
       "PlayTimeDiff      444\n",
       "SideofField       528\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of missing data points per column\n",
    "nfl_missing_values_count = nfl_data.isnull().sum()\n",
    "\n",
    "# look at the # of missing points in the first ten columns\n",
    "nfl_missing_values_count[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "84455c7e-6c63-4e08-a7b4-7520a61072f9",
    "_uuid": "054ba8782a7b0555336eddb90c985fb638beac4d"
   },
   "source": [
    "That seems like a lot! It might be helpful to see what percentage of the values in our dataset were missing to give us a better sense of the scale of this problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "fb77dd56-192e-48be-8181-2082985dd5a2",
    "_uuid": "d6e65ba197893f29d9dce0b0cd1c75017b60db09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.87214126835169"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many total missing values do we have?\n",
    "total_cells = np.product(nfl_data.shape)\n",
    "total_missing = nfl_missing_values_count.sum()\n",
    "\n",
    "# percent of data that is missing\n",
    "(total_missing/total_cells) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "31daa324-9215-4930-985c-01dee717b6b8",
    "_uuid": "3331fa42efa16f3db2e8e196411f351c5f8309f5"
   },
   "source": [
    "Wow, almost a quarter of the cells in this dataset are empty! In the next step, we're going to take a closer look at some of the columns with missing values and try to figure out what might be going on with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "f20a9474-41ee-4ecd-a2f4-1ab147fc8655",
    "_uuid": "64487760aa1afaaa8b8a4d1f95206773759db101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permit Number                                  0\n",
      "Permit Type                                    0\n",
      "Permit Type Definition                         0\n",
      "Permit Creation Date                           0\n",
      "Block                                          0\n",
      "Lot                                            0\n",
      "Street Number                                  0\n",
      "Street Number Suffix                      196684\n",
      "Street Name                                    0\n",
      "Street Suffix                               2768\n",
      "Unit                                      169421\n",
      "Unit Suffix                               196939\n",
      "Description                                  290\n",
      "Current Status                                 0\n",
      "Current Status Date                            0\n",
      "Filed Date                                     0\n",
      "Issued Date                                14940\n",
      "Completed Date                            101709\n",
      "First Construction Document Date           14946\n",
      "Structural Notification                   191978\n",
      "Number of Existing Stories                 42784\n",
      "Number of Proposed Stories                 42868\n",
      "Voluntary Soft-Story Retrofit             198865\n",
      "Fire Only Permit                          180073\n",
      "Permit Expiration Date                     51880\n",
      "Estimated Cost                             38066\n",
      "Revised Cost                                6066\n",
      "Existing Use                               41114\n",
      "Existing Units                             51538\n",
      "Proposed Use                               42439\n",
      "Proposed Units                             50911\n",
      "Plansets                                   37309\n",
      "TIDF Compliance                           198898\n",
      "Existing Construction Type                 43366\n",
      "Existing Construction Type Description     43366\n",
      "Proposed Construction Type                 43162\n",
      "Proposed Construction Type Description     43162\n",
      "Site Permit                               193541\n",
      "Supervisor District                         1717\n",
      "Neighborhoods - Analysis Boundaries         1725\n",
      "Zipcode                                     1716\n",
      "Location                                    1700\n",
      "Record ID                                      0\n",
      "dtype: int64 \n",
      "\n",
      "26.2600231506 % of the data are missing.\n"
     ]
    }
   ],
   "source": [
    "# your turn! Find out what percent of the sf_permit dataset is missing\n",
    "sf_missing_values_count = sf_permits.isnull().sum()\n",
    "print(sf_permits.isnull().sum(), \"\\n\")\n",
    "total_cells = np.product(sf_permits.shape)\n",
    "total_missing = sf_missing_values_count.sum()\n",
    "print((total_missing/total_cells) * 100, \"% of the data are missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "62b9f021-5b80-43e2-bf60-8e0d5e22d572",
    "_uuid": "032a618abb98a28e60ab84376cf21402178f995d"
   },
   "source": [
    "# Figure out why the data is missing\n",
    "____\n",
    " \n",
    "This is the point at which we get into the part of data science that I like to call \"data intution\", by which I mean \"really looking at your data and trying to figure out why it is the way it is and how that will affect your analysis\". It can be a frustrating part of data science, especially if you're newer to the field and don't have a lot of experience. For dealing with missing values, you'll need to **use your intution to figure out why the value is missing**. One of the most important question you can ask yourself to help figure this out is this:\n",
    "\n",
    "> ### Is this value missing becuase it wasn't recorded or becuase it dosen't exist?\n",
    "\n",
    "If a value is missing becuase it doens't exist (like the height of the oldest child of someone who doesn't have any children) then it doesn't make sense to try and guess what it might be. These values you probalby do want to keep as NaN. On the other hand, **if a value is missing becuase it wasn't recorded, then you can try to guess what it might have been based on the other values in that column and row**. (This is called \"imputation\" and we'll learn how to do it next! :)\n",
    "\n",
    "Let's work through an example. Looking at the number of missing values in the nfl_data dataframe, I notice that the column `TimesSec` has a lot of missing values in it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "77739e82-8d32-4374-84bf-a924b6065168",
    "_uuid": "b65aea6046964806e44422c057bce8bd7f8e59d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                0\n",
       "GameID              0\n",
       "Drive               0\n",
       "qtr                 0\n",
       "down            61154\n",
       "time              224\n",
       "TimeUnder           0\n",
       "TimeSecs          224\n",
       "PlayTimeDiff      444\n",
       "SideofField       528\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the # of missing points in the first ten columns\n",
    "nfl_missing_values_count[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1b17f4c9-dcab-4857-82f9-a2534e804c91",
    "_uuid": "5cff158285ab37a89b80dcc35d5c690cdb42d3a4"
   },
   "source": [
    "By looking at [the documentation](https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016), I can see that this column has information on the number of seconds left in the game when the play was made. This means that these values are probably missing because they were not recorded, rather than because they don't exist. So, it would make sense for us to try and guess what they should be rather than just leaving them as NA's.\n",
    "\n",
    "On the other hand, there are other fields, like `PenalizedTeam` that also have lot of missing fields. In this case, though, the field is missing because if there was no penalty then it doesn't make sense to say *which* team was penalized. For this column, it would make more sense to either leave it empty or to add a third value like \"neither\" and use that to replace the NA's.\n",
    "\n",
    "> **Tip:** This is a great place to read over the dataset documentation if you haven't already! If you're working with a dataset that you've gotten from another person, you can also try reaching out to them to get more information.\n",
    "\n",
    "If you're doing very careful data analysis, this is the point at which you'd look at each column individually to figure out the best strategy for filling those missing values. For the rest of this notebook, we'll cover some \"quick and dirty\" techniques that can help you with missing values but will probably also end up removing some useful information or adding some noise to your data.\n",
    "\n",
    "## Your turn!\n",
    "\n",
    "* Look at the columns `Street Number Suffix` and `Zipcode` from the `sf_permits` datasets. Both of these contain missing values. Which, if either, of these are missing because they don't exist? Which, if either, are missing because they weren't recorded?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ea022b62-6419-47e7-973e-c3e707e2795f",
    "_uuid": "3f72f46f2464c7cd12f5eb2a752746ce1cd0b5a7"
   },
   "source": [
    "# Drop missing values\n",
    "___\n",
    "\n",
    "If you're in a hurry or don't have a reason to figure out why your values are missing, one option you have is to just remove any rows or columns that contain missing values. (Note: I don't generally recommend this approch for important projects! It's usually worth it to take the time to go through your data and really look at all the columns with missing values one-by-one to really get to know your dataset.)  \n",
    "\n",
    "If you're sure you want to drop rows with missing values, pandas does have a handy function, `dropna()` to help you do this. Let's try it out on our NFL dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ad0ac9a2-2854-4bb7-8886-8eee7fad8756",
    "_uuid": "ad8ef7825ba9bce3472a47d7c5242a4522f14065",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove all the rows that contain a missing value\n",
    "nfl_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e0545655-3d37-448b-ae56-2c7707cd805d",
    "_uuid": "33eb849e076d2a4d0c409f58d78b5f303879b1b3"
   },
   "source": [
    "Oh dear, it looks like that's removed all our data! ðŸ˜± This is because every row in our dataset had at least one missing value. We might have better luck removing all the *columns* that have at least one missing value instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "97709ad4-f7b8-4cd0-8911-56e14db904ae",
    "_uuid": "87c569672854fe23e1ee9376ef3115ba4712cbf5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove all columns with at least one missing value\n",
    "columns_with_na_dropped = nfl_data.dropna(axis=1)\n",
    "columns_with_na_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0e51b19b-c44d-4487-8417-725d2b911739",
    "_uuid": "e60a092d2799851aa725eadf28b197022a6b127f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just how much data did we lose?\n",
    "print(\"Columns in original dataset: %d \\n\" % nfl_data.shape[1])\n",
    "print(\"Columns with na's dropped: %d\" % columns_with_na_dropped.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f417c614-f77f-45eb-b16b-fdc0be936502",
    "_uuid": "bac84fee4ca849e54839c716c43dddfbb559954b"
   },
   "source": [
    "We've lost quite a bit of data, but at this point we have successfully removed all the `NaN`'s from our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0fe94654-7dad-4e8d-bbbb-e65e2bb2f767",
    "_uuid": "8207912f74712835283f7e1b30dad0471ee2e1fc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your turn! Try removing all the rows from the sf_permits dataset that contain missing values. How many are left?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7ec643e1-abba-4683-b794-a1924e657501",
    "_uuid": "f804c0448b18b6d411ddf8452d15abba8292fffa",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now try removing all the columns with empty values. Now how much of your data is left?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1dbe153d-7b30-4ad8-80ad-a4c7fb53928e",
    "_uuid": "eb1ef8d47d9ebed77c3d21eca24708708ed4d45f"
   },
   "source": [
    "# Filling in missing values automatically\n",
    "_____\n",
    "\n",
    "Another option is to try and fill in the missing values. For this next bit, I'm getting a small sub-section of the NFL data so that it will print well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "76fd83fb-a6d9-4c03-8c94-a111ee529881",
    "_uuid": "e0944282c73a63513d5345689ddd6a9da0fc8547",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a small subset of the NFL dataset\n",
    "subset_nfl_data = nfl_data.loc[:, 'EPA':'Season'].head()\n",
    "subset_nfl_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "527c8703-4b29-459d-af7d-5505da36016b",
    "_uuid": "f8cfe916904af3265d8ecc4f791f9f62e34ff458"
   },
   "source": [
    "We can use the Panda's fillna() function to fill in missing values in a dataframe for us. One option we have is to specify what we want the `NaN` values to be replaced with. Here, I'm saying that I would like to replace all the `NaN` values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c01ed989-8901-43c8-afa3-6ca36605dfb5",
    "_uuid": "77eac530ce398b8c13eb7886f86bce48fd997f34",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace all NA's with 0\n",
    "subset_nfl_data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1103b725-c823-4f40-9bda-e97997856339",
    "_uuid": "bec603202c6bfaae7a49b4a4042f37019ad1d801"
   },
   "source": [
    "I could also be a bit more savvy and replace missing values with whatever value comes directly after it in the same column. (This makes a lot of sense for datasets where the observations have some sort of logical order to them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "90ddac9b-ee20-492e-b437-0519c97ca317",
    "_uuid": "afba99aa7897539e9a0af77dce03daab94d0ca68",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace all NA's the value that comes directly after it in the same column, \n",
    "# then replace all the reamining na's with 0\n",
    "subset_nfl_data.fillna(method = 'bfill', axis=0).fillna(\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "980e5d67-7e9c-41a3-b17e-51d87e9da9cf",
    "_uuid": "1f8ac8b52f2933612e315f06a53185e164e6c5bc"
   },
   "source": [
    "Filling in missing values is also known as \"imputation\", and you can find more exercises on it [in this lesson, also linked under the \"More practice!\" section](https://www.kaggle.com/dansbecker/handling-missing-values). First, however, why don't you try replacing some of the missing values in the sf_permit dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "da426397-7e17-40ce-a0d4-ca6d39e47498",
    "_uuid": "f7d403c19eaf31ee0a4e04b9e1119eda96a9f95c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your turn! Try replacing all the NaN's in the sf_permit data with the one that\n",
    "# comes directly after it and then "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4f37fce-4d08-409e-bbbd-6a26c3bbc6ee",
    "_uuid": "52b0af56e3c77db96056e9acd785f8f435f7caf5"
   },
   "source": [
    "And that's it for today! If you have any questions, be sure to post them in the comments below or [on the forums](https://www.kaggle.com/questions-and-answers). \n",
    "\n",
    "Remember that your notebook is private by default, and in order to share it with other people or ask for help with it, you'll need to make it public. First, you'll need to save a version of your notebook that shows your current work by hitting the \"Commit & Run\" button. (Your work is saved automatically, but versioning your work lets you go back and look at what it was like at the point you saved it. It also let's you share a nice compiled notebook instead of just the raw code.) Then, once your notebook is finished running, you can go to the Settings tab in the panel to the left (you may have to expand it by hitting the [<] button next to the \"Commit & Run\" button) and setting the \"Visibility\" dropdown to \"Public\".\n",
    "\n",
    "# More practice!\n",
    "___\n",
    "\n",
    "If you're looking for more practice handling missing values, check out these extra-credit\\* exercises:\n",
    "\n",
    "* [Handling Missing Values](https://www.kaggle.com/dansbecker/handling-missing-values): In this notebook Dan shows you several approaches to imputing missing data using scikit-learn's imputer. \n",
    "* Look back at the `Zipcode` column in the `sf_permits` dataset, which has some missing values. How would you go about figuring out what the actual zipcode of each address should be? (You might try using another dataset, like the [OpenAddresses dataset](https://www.kaggle.com/openaddresses/openaddresses-us-west).) \n",
    "\n",
    "\\* no actual credit is given for completing the challenge, you just learn how to clean data real good :P"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
