{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from konlpy.tag import Twitter \n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hangul = re.compile('[^ ㄱ-ㅣ가-힣]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../../../../00_dataset_archive/nlp/news_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[이투데이] 정다운 기자(gamja@etoday.co.kr)&lt;br&gt;&lt;br&gt;1991년...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[아시아경제 김민진 기자] 중소기업 경영후계자들로 구성된 한국가업승계기업협의회(회장...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>신사업 경영 전면에서 총대메기웅진, 씽크빅 신사업 주축으로교원, 신성장동력 직접 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[아시아경제 권성회 기자] 체리부로는 계열사 체리푸드(구 동양종합식품) 주식 50만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[아시아경제 이은정 기자] 하림(대표 이문용)과 동양종합식품(대표 강상훈)이 15일...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  [이투데이] 정다운 기자(gamja@etoday.co.kr)<br><br>1991년...\n",
       "1  [아시아경제 김민진 기자] 중소기업 경영후계자들로 구성된 한국가업승계기업협의회(회장...\n",
       "2  신사업 경영 전면에서 총대메기웅진, 씽크빅 신사업 주축으로교원, 신성장동력 직접 이...\n",
       "3  [아시아경제 권성회 기자] 체리부로는 계열사 체리푸드(구 동양종합식품) 주식 50만...\n",
       "4  [아시아경제 이은정 기자] 하림(대표 이문용)과 동양종합식품(대표 강상훈)이 15일..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['content']][:10000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tmp = data[['content']][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4678ce52cf48948f9e365e6ae23af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "\n",
    "for article in tqdm_notebook(data_tmp['content']):\n",
    "    article = hangul.sub(' ', article)\n",
    "    article = tagger.morphs(article, stem=True)\n",
    "    article = [x for x in article if len(x) > 1]\n",
    "    docs.append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이투데이',\n",
       " '정다운',\n",
       " '기자',\n",
       " '설립',\n",
       " '체리',\n",
       " '부로',\n",
       " '원종',\n",
       " '부터',\n",
       " '유통',\n",
       " '판매',\n",
       " '이르는',\n",
       " '수직',\n",
       " '계열',\n",
       " '완성한',\n",
       " '육계',\n",
       " '가공업',\n",
       " '체다',\n",
       " '하림',\n",
       " '마니커',\n",
       " '이어',\n",
       " '업계',\n",
       " '위로',\n",
       " '평가',\n",
       " '받아',\n",
       " '지만',\n",
       " '매출',\n",
       " '영업',\n",
       " '이익',\n",
       " '실속',\n",
       " '따져',\n",
       " '보면',\n",
       " '이후',\n",
       " '로는',\n",
       " '확실히',\n",
       " '업계',\n",
       " '상위',\n",
       " '이라는',\n",
       " '강조하고',\n",
       " '있다',\n",
       " '지난해',\n",
       " '상장',\n",
       " '하며',\n",
       " '업계',\n",
       " '에서',\n",
       " '만에',\n",
       " '코스닥시장',\n",
       " '진입',\n",
       " '체리',\n",
       " '부로',\n",
       " '공모',\n",
       " '청약',\n",
       " '이라는',\n",
       " '높은',\n",
       " '경쟁률',\n",
       " '기록',\n",
       " '유통',\n",
       " '계열',\n",
       " '사인',\n",
       " '처갓집',\n",
       " '양념치킨',\n",
       " '이끌어',\n",
       " '경영인',\n",
       " '김강',\n",
       " '체리',\n",
       " '부로',\n",
       " '전무',\n",
       " '최근',\n",
       " '체리',\n",
       " '부로',\n",
       " '최대',\n",
       " '주주',\n",
       " '자리',\n",
       " '에까지',\n",
       " '오른',\n",
       " '점도',\n",
       " '본격',\n",
       " '경영',\n",
       " '승계',\n",
       " '이후',\n",
       " '변화',\n",
       " '기대',\n",
       " '하는',\n",
       " '부분',\n",
       " '이다',\n",
       " '역성',\n",
       " '없는',\n",
       " '육계',\n",
       " '산업',\n",
       " '수직',\n",
       " '계열',\n",
       " '이점',\n",
       " '체리',\n",
       " '부로',\n",
       " '공모',\n",
       " '흥행',\n",
       " '육계',\n",
       " '산업',\n",
       " '독특한',\n",
       " '특성',\n",
       " '에서',\n",
       " '기인',\n",
       " '국내',\n",
       " '도계',\n",
       " '소비',\n",
       " '선호',\n",
       " '도의',\n",
       " '꾸준한',\n",
       " '증가',\n",
       " '이후',\n",
       " '평균',\n",
       " '증가하고',\n",
       " '있다',\n",
       " '특히',\n",
       " '닭고기',\n",
       " '기타',\n",
       " '주요',\n",
       " '육류',\n",
       " '보다',\n",
       " '유통',\n",
       " '신선도',\n",
       " '미치는',\n",
       " '영향',\n",
       " '국내',\n",
       " '호도',\n",
       " '절대',\n",
       " '이다',\n",
       " '마다',\n",
       " '반복되는',\n",
       " '전염병',\n",
       " '파동',\n",
       " '에도',\n",
       " '국내',\n",
       " '육계',\n",
       " '시장',\n",
       " '역성',\n",
       " '장이',\n",
       " '없었',\n",
       " '배경',\n",
       " '이다',\n",
       " '특히',\n",
       " '국내',\n",
       " '육계',\n",
       " '산업',\n",
       " '에서는',\n",
       " '경쟁력',\n",
       " '없는',\n",
       " '기업',\n",
       " '급격',\n",
       " '하게',\n",
       " '도태',\n",
       " '면서',\n",
       " '과거',\n",
       " '여개',\n",
       " '회사',\n",
       " '대부분',\n",
       " '정리되',\n",
       " '현재',\n",
       " '남은',\n",
       " '상황',\n",
       " '이다',\n",
       " '마저도',\n",
       " '상위',\n",
       " '기업',\n",
       " '근소',\n",
       " '차이',\n",
       " '점유',\n",
       " '대부분',\n",
       " '독식',\n",
       " '하며',\n",
       " '경쟁',\n",
       " '하고',\n",
       " '있다',\n",
       " '특히',\n",
       " '체리',\n",
       " '부로',\n",
       " '업계',\n",
       " '위인',\n",
       " '하림',\n",
       " '이어',\n",
       " '방면',\n",
       " '에서',\n",
       " '수직',\n",
       " '계열',\n",
       " '완성했',\n",
       " '원종',\n",
       " '사료',\n",
       " '도계',\n",
       " '방역',\n",
       " '열사',\n",
       " '판매',\n",
       " '방면',\n",
       " '에서',\n",
       " '직영',\n",
       " '비율',\n",
       " '높고',\n",
       " '재료',\n",
       " '자급',\n",
       " '까지',\n",
       " '가능한',\n",
       " '수직',\n",
       " '계열',\n",
       " '완성',\n",
       " '을수록',\n",
       " '경쟁력',\n",
       " '우수하다',\n",
       " '까지',\n",
       " '육계',\n",
       " '산업',\n",
       " '대기업',\n",
       " '시장점유율',\n",
       " '에서',\n",
       " '이던',\n",
       " '체리',\n",
       " '부로',\n",
       " '지난해',\n",
       " '위인',\n",
       " '마니커',\n",
       " '시장점유율',\n",
       " '바짝',\n",
       " '따라잡',\n",
       " '으며',\n",
       " '점유',\n",
       " '올랐',\n",
       " '육계',\n",
       " '산업',\n",
       " '대형화',\n",
       " '기업',\n",
       " '가속도',\n",
       " '붙으',\n",
       " '대기업',\n",
       " '시장점유율',\n",
       " '이전',\n",
       " '에서',\n",
       " '지난해',\n",
       " '이상',\n",
       " '으로',\n",
       " '상승세',\n",
       " '하림',\n",
       " '이어',\n",
       " '유일하',\n",
       " '수직',\n",
       " '계열',\n",
       " '완성한',\n",
       " '체리',\n",
       " '부로',\n",
       " '공모',\n",
       " '청약',\n",
       " '엄청난',\n",
       " '경쟁',\n",
       " '보인',\n",
       " '배경',\n",
       " '이다',\n",
       " '체리',\n",
       " '부로',\n",
       " '유통',\n",
       " '단계',\n",
       " '채널',\n",
       " '핵심',\n",
       " '브랜드',\n",
       " '확보',\n",
       " '기반',\n",
       " '으로',\n",
       " '내부',\n",
       " '매출',\n",
       " '지난해',\n",
       " '에서',\n",
       " '올해',\n",
       " '성장',\n",
       " '예상하고',\n",
       " '있다',\n",
       " '이후',\n",
       " '평균',\n",
       " '매출',\n",
       " '성장',\n",
       " '지난해',\n",
       " '매출',\n",
       " '영업',\n",
       " '이익',\n",
       " '각각',\n",
       " '기록',\n",
       " '전염병',\n",
       " '파동',\n",
       " '마다',\n",
       " '흔들리는',\n",
       " '주가',\n",
       " '실적',\n",
       " '영향',\n",
       " '없어',\n",
       " '닭고기',\n",
       " '회사',\n",
       " '마다',\n",
       " '반복되는',\n",
       " '조류인플루엔자',\n",
       " '전염병',\n",
       " '파동',\n",
       " '주가',\n",
       " '크게',\n",
       " '흔들린',\n",
       " '체리',\n",
       " '부로',\n",
       " '역시',\n",
       " '상장',\n",
       " '앞두고',\n",
       " '지난해',\n",
       " '사태',\n",
       " '지면',\n",
       " '종업',\n",
       " '하림',\n",
       " '동우',\n",
       " '테이블',\n",
       " '마니커',\n",
       " '주가',\n",
       " '크게',\n",
       " '하락',\n",
       " '가치',\n",
       " '평가',\n",
       " '먹었',\n",
       " '달걀',\n",
       " '살충제',\n",
       " '성분',\n",
       " '사태',\n",
       " '실제',\n",
       " '실적',\n",
       " '에도',\n",
       " '영향',\n",
       " '미쳤',\n",
       " '이외',\n",
       " '에도',\n",
       " '최호',\n",
       " '호식',\n",
       " '마리',\n",
       " '치킨',\n",
       " '회장',\n",
       " '성추행',\n",
       " '혐의',\n",
       " '대대',\n",
       " '으로',\n",
       " '보도되는',\n",
       " '프랜차이즈',\n",
       " '시장',\n",
       " '전반',\n",
       " '대한',\n",
       " '문제',\n",
       " '사회',\n",
       " '이슈',\n",
       " '부각',\n",
       " '되는',\n",
       " '재도',\n",
       " '있었',\n",
       " '당시',\n",
       " '상장',\n",
       " '간담',\n",
       " '에서',\n",
       " '체리',\n",
       " '부로',\n",
       " '측은',\n",
       " '전염병',\n",
       " '파동',\n",
       " '이후',\n",
       " '에는',\n",
       " '공급',\n",
       " '부족',\n",
       " '발생해',\n",
       " '오히려',\n",
       " '매출',\n",
       " '느는',\n",
       " '현상',\n",
       " '반복된',\n",
       " '달걀',\n",
       " '살충제',\n",
       " '파동',\n",
       " '해당',\n",
       " '기간',\n",
       " '실적',\n",
       " '영향',\n",
       " '주지',\n",
       " '전반',\n",
       " '매출',\n",
       " '수준',\n",
       " '에는',\n",
       " '변화',\n",
       " '없다',\n",
       " '설명했',\n",
       " '경영',\n",
       " '시동',\n",
       " '주가',\n",
       " '회복',\n",
       " '탄력',\n",
       " '관심',\n",
       " '끌었',\n",
       " '상장',\n",
       " '달리',\n",
       " '체리',\n",
       " '부로',\n",
       " '주가',\n",
       " '상장',\n",
       " '시초',\n",
       " '회복하지',\n",
       " '지지',\n",
       " '부진',\n",
       " '하락',\n",
       " '보여',\n",
       " '에는',\n",
       " '주가',\n",
       " '까지',\n",
       " '내려가기',\n",
       " '그러나',\n",
       " '최근',\n",
       " '경영인',\n",
       " '으로',\n",
       " '최대',\n",
       " '주주',\n",
       " '변경',\n",
       " '소식',\n",
       " '전해진',\n",
       " '주가',\n",
       " '소폭',\n",
       " '회복',\n",
       " '보이',\n",
       " '있다',\n",
       " '지난',\n",
       " '체리',\n",
       " '부로',\n",
       " '최대',\n",
       " '주주',\n",
       " '김인식',\n",
       " '에서',\n",
       " '한국',\n",
       " '일오삼',\n",
       " '으로',\n",
       " '변경',\n",
       " '다고',\n",
       " '공시',\n",
       " '최대',\n",
       " '주주',\n",
       " '특수',\n",
       " '관계',\n",
       " '한국',\n",
       " '일오삼이',\n",
       " '장내',\n",
       " '매수',\n",
       " '따른',\n",
       " '이다',\n",
       " '한국',\n",
       " '일오삼',\n",
       " '김인식',\n",
       " '체리',\n",
       " '부로',\n",
       " '회장',\n",
       " '아들',\n",
       " '김강',\n",
       " '전무',\n",
       " '최대',\n",
       " '주주',\n",
       " '있는',\n",
       " '회사',\n",
       " '전무',\n",
       " '한국',\n",
       " '일오삼',\n",
       " '보유',\n",
       " '하고',\n",
       " '있다',\n",
       " '이번',\n",
       " '매수',\n",
       " '한국',\n",
       " '일오삼',\n",
       " '체리',\n",
       " '부로',\n",
       " '주식',\n",
       " '보유',\n",
       " '하게',\n",
       " '전무',\n",
       " '개인',\n",
       " '명의',\n",
       " '체리',\n",
       " '부로',\n",
       " '보유',\n",
       " '하고',\n",
       " '있다',\n",
       " '체리',\n",
       " '부로',\n",
       " '향후',\n",
       " '마트',\n",
       " '전통',\n",
       " '유통',\n",
       " '보다는',\n",
       " '가정',\n",
       " '간편식',\n",
       " '시장',\n",
       " '진출해',\n",
       " '재료',\n",
       " '시장',\n",
       " '에서',\n",
       " '벗어',\n",
       " '소비자',\n",
       " '대상',\n",
       " '집중한',\n",
       " '다는',\n",
       " '방침',\n",
       " '이다',\n",
       " '지난해',\n",
       " '동양',\n",
       " '종합',\n",
       " '식품',\n",
       " '인수',\n",
       " '역시',\n",
       " '해당',\n",
       " '부분',\n",
       " '강화하기',\n",
       " '위한',\n",
       " '방안',\n",
       " '이다',\n",
       " '지난해',\n",
       " '간담',\n",
       " '직접',\n",
       " '진행한',\n",
       " '전무',\n",
       " '현재',\n",
       " '국내',\n",
       " '육계',\n",
       " '시장',\n",
       " '지속',\n",
       " '으로',\n",
       " '커지',\n",
       " '있기',\n",
       " '때문',\n",
       " '이를',\n",
       " '대응하는',\n",
       " '집중하고',\n",
       " '있지',\n",
       " '향후',\n",
       " '제주도',\n",
       " '계장',\n",
       " '활용한',\n",
       " '중국',\n",
       " '수출',\n",
       " '모색할',\n",
       " '이라고',\n",
       " '말했']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s : %(levelname)s : %(message)s', \n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 500\n",
    "min_word_count = 10\n",
    "num_workers = 1\n",
    "context = 15\n",
    "downsampling = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-08 19:40:40,588 : INFO : collecting all words and their counts\n",
      "2019-01-08 19:40:40,590 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-01-08 19:40:41,712 : INFO : collected 56423 word types from a corpus of 3298438 raw words and 10000 sentences\n",
      "2019-01-08 19:40:41,713 : INFO : Loading a fresh vocabulary\n",
      "2019-01-08 19:40:41,990 : INFO : min_count=10 retains 19427 unique words (34% of original 56423, drops 36996)\n",
      "2019-01-08 19:40:41,991 : INFO : min_count=10 leaves 3188887 word corpus (96% of original 3298438, drops 109551)\n",
      "2019-01-08 19:40:42,087 : INFO : deleting the raw counts dictionary of 56423 items\n",
      "2019-01-08 19:40:42,090 : INFO : sample=0.001 downsamples 24 most-common words\n",
      "2019-01-08 19:40:42,091 : INFO : downsampling leaves estimated 3033542 word corpus (95.1% of prior 3188887)\n",
      "2019-01-08 19:40:42,215 : INFO : estimated required memory for 19427 words and 500 dimensions: 87421500 bytes\n",
      "2019-01-08 19:40:42,218 : INFO : resetting layer weights\n",
      "2019-01-08 19:40:42,891 : INFO : training model with 1 workers on 19427 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=5 window=15\n",
      "2019-01-08 19:40:43,938 : INFO : EPOCH 1 - PROGRESS: at 3.93% examples, 103124 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:40:44,988 : INFO : EPOCH 1 - PROGRESS: at 8.45% examples, 112334 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:40:45,992 : INFO : EPOCH 1 - PROGRESS: at 13.43% examples, 114818 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:40:47,001 : INFO : EPOCH 1 - PROGRESS: at 18.70% examples, 115673 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:40:48,032 : INFO : EPOCH 1 - PROGRESS: at 23.77% examples, 117029 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:40:49,095 : INFO : EPOCH 1 - PROGRESS: at 25.65% examples, 119912 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:40:50,170 : INFO : EPOCH 1 - PROGRESS: at 30.00% examples, 121149 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:40:51,182 : INFO : EPOCH 1 - PROGRESS: at 33.89% examples, 121286 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:40:52,500 : INFO : EPOCH 1 - PROGRESS: at 36.09% examples, 114605 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:40:53,691 : INFO : EPOCH 1 - PROGRESS: at 38.08% examples, 109888 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:40:54,787 : INFO : EPOCH 1 - PROGRESS: at 38.95% examples, 103122 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:40:56,014 : INFO : EPOCH 1 - PROGRESS: at 39.57% examples, 96109 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:40:57,132 : INFO : EPOCH 1 - PROGRESS: at 41.17% examples, 93410 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:40:58,266 : INFO : EPOCH 1 - PROGRESS: at 42.58% examples, 90011 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:40:59,334 : INFO : EPOCH 1 - PROGRESS: at 44.22% examples, 88860 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:00,368 : INFO : EPOCH 1 - PROGRESS: at 45.33% examples, 86507 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:01,429 : INFO : EPOCH 1 - PROGRESS: at 47.44% examples, 86354 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:02,455 : INFO : EPOCH 1 - PROGRESS: at 48.62% examples, 84136 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:03,525 : INFO : EPOCH 1 - PROGRESS: at 50.24% examples, 82728 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:41:04,536 : INFO : EPOCH 1 - PROGRESS: at 52.61% examples, 82628 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:05,558 : INFO : EPOCH 1 - PROGRESS: at 54.59% examples, 82342 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:06,649 : INFO : EPOCH 1 - PROGRESS: at 56.06% examples, 80446 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:07,714 : INFO : EPOCH 1 - PROGRESS: at 57.55% examples, 78714 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:08,835 : INFO : EPOCH 1 - PROGRESS: at 59.04% examples, 77387 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:09,963 : INFO : EPOCH 1 - PROGRESS: at 60.88% examples, 76068 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:11,072 : INFO : EPOCH 1 - PROGRESS: at 63.84% examples, 75572 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:12,163 : INFO : EPOCH 1 - PROGRESS: at 66.85% examples, 74885 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:13,291 : INFO : EPOCH 1 - PROGRESS: at 69.03% examples, 73581 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:41:14,385 : INFO : EPOCH 1 - PROGRESS: at 70.88% examples, 72689 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:15,456 : INFO : EPOCH 1 - PROGRESS: at 73.40% examples, 72490 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:16,470 : INFO : EPOCH 1 - PROGRESS: at 77.00% examples, 72987 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:41:17,480 : INFO : EPOCH 1 - PROGRESS: at 81.56% examples, 73950 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:18,516 : INFO : EPOCH 1 - PROGRESS: at 86.57% examples, 75045 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:19,564 : INFO : EPOCH 1 - PROGRESS: at 89.99% examples, 75588 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:20,595 : INFO : EPOCH 1 - PROGRESS: at 93.61% examples, 76343 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:21,596 : INFO : EPOCH 1 - PROGRESS: at 98.14% examples, 77148 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:22,053 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-08 19:41:22,054 : INFO : EPOCH - 1 : training on 3298438 raw words (3033393 effective words) took 39.2s, 77476 effective words/s\n",
      "2019-01-08 19:41:23,119 : INFO : EPOCH 2 - PROGRESS: at 3.66% examples, 92671 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:24,148 : INFO : EPOCH 2 - PROGRESS: at 7.58% examples, 99392 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:25,154 : INFO : EPOCH 2 - PROGRESS: at 12.30% examples, 105646 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:26,169 : INFO : EPOCH 2 - PROGRESS: at 15.74% examples, 99600 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:27,176 : INFO : EPOCH 2 - PROGRESS: at 20.41% examples, 99951 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:28,233 : INFO : EPOCH 2 - PROGRESS: at 24.19% examples, 101600 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:29,252 : INFO : EPOCH 2 - PROGRESS: at 25.79% examples, 105791 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:30,276 : INFO : EPOCH 2 - PROGRESS: at 30.33% examples, 108351 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:31,349 : INFO : EPOCH 2 - PROGRESS: at 34.32% examples, 110004 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:32,354 : INFO : EPOCH 2 - PROGRESS: at 37.02% examples, 110915 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:41:33,413 : INFO : EPOCH 2 - PROGRESS: at 39.57% examples, 111039 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:41:34,421 : INFO : EPOCH 2 - PROGRESS: at 42.29% examples, 111210 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:35,477 : INFO : EPOCH 2 - PROGRESS: at 45.25% examples, 112001 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:36,511 : INFO : EPOCH 2 - PROGRESS: at 48.15% examples, 112634 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:37,559 : INFO : EPOCH 2 - PROGRESS: at 51.58% examples, 113044 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:41:38,583 : INFO : EPOCH 2 - PROGRESS: at 54.82% examples, 113496 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:39,602 : INFO : EPOCH 2 - PROGRESS: at 58.86% examples, 113925 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:40,610 : INFO : EPOCH 2 - PROGRESS: at 63.43% examples, 114317 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:41,657 : INFO : EPOCH 2 - PROGRESS: at 69.28% examples, 114596 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:42,704 : INFO : EPOCH 2 - PROGRESS: at 71.95% examples, 112611 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:43,715 : INFO : EPOCH 2 - PROGRESS: at 75.48% examples, 111499 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:44,745 : INFO : EPOCH 2 - PROGRESS: at 79.46% examples, 110796 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:45,766 : INFO : EPOCH 2 - PROGRESS: at 85.18% examples, 111249 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:46,780 : INFO : EPOCH 2 - PROGRESS: at 89.68% examples, 111759 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:47,795 : INFO : EPOCH 2 - PROGRESS: at 93.31% examples, 111488 words/s, in_qsize 1, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-08 19:41:48,812 : INFO : EPOCH 2 - PROGRESS: at 97.69% examples, 111275 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:49,296 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-08 19:41:49,297 : INFO : EPOCH - 2 : training on 3298438 raw words (3033657 effective words) took 27.2s, 111390 effective words/s\n",
      "2019-01-08 19:41:50,309 : INFO : EPOCH 3 - PROGRESS: at 4.83% examples, 124529 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:51,315 : INFO : EPOCH 3 - PROGRESS: at 9.14% examples, 125827 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:52,382 : INFO : EPOCH 3 - PROGRESS: at 15.00% examples, 126875 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:53,438 : INFO : EPOCH 3 - PROGRESS: at 20.76% examples, 125940 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:54,489 : INFO : EPOCH 3 - PROGRESS: at 24.33% examples, 124411 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:55,558 : INFO : EPOCH 3 - PROGRESS: at 25.58% examples, 117383 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:56,659 : INFO : EPOCH 3 - PROGRESS: at 26.04% examples, 105925 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:57,726 : INFO : EPOCH 3 - PROGRESS: at 28.99% examples, 101277 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:41:58,778 : INFO : EPOCH 3 - PROGRESS: at 32.40% examples, 100539 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:41:59,845 : INFO : EPOCH 3 - PROGRESS: at 34.82% examples, 99308 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:00,893 : INFO : EPOCH 3 - PROGRESS: at 36.84% examples, 97735 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:01,916 : INFO : EPOCH 3 - PROGRESS: at 38.74% examples, 96471 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:02,971 : INFO : EPOCH 3 - PROGRESS: at 41.29% examples, 97910 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:04,092 : INFO : EPOCH 3 - PROGRESS: at 43.86% examples, 97534 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:05,147 : INFO : EPOCH 3 - PROGRESS: at 45.70% examples, 96892 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:06,195 : INFO : EPOCH 3 - PROGRESS: at 48.15% examples, 96335 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:07,236 : INFO : EPOCH 3 - PROGRESS: at 50.74% examples, 96168 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:08,276 : INFO : EPOCH 3 - PROGRESS: at 53.13% examples, 95137 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:42:09,280 : INFO : EPOCH 3 - PROGRESS: at 55.16% examples, 94287 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:10,330 : INFO : EPOCH 3 - PROGRESS: at 58.44% examples, 94150 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:11,346 : INFO : EPOCH 3 - PROGRESS: at 62.22% examples, 94967 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:12,398 : INFO : EPOCH 3 - PROGRESS: at 68.10% examples, 96045 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:42:13,402 : INFO : EPOCH 3 - PROGRESS: at 72.73% examples, 97170 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:14,455 : INFO : EPOCH 3 - PROGRESS: at 77.70% examples, 98122 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:15,498 : INFO : EPOCH 3 - PROGRESS: at 83.67% examples, 99311 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:16,557 : INFO : EPOCH 3 - PROGRESS: at 88.68% examples, 100371 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:17,631 : INFO : EPOCH 3 - PROGRESS: at 93.31% examples, 101265 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:18,698 : INFO : EPOCH 3 - PROGRESS: at 98.14% examples, 101565 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:19,167 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-08 19:42:19,168 : INFO : EPOCH - 3 : training on 3298438 raw words (3033168 effective words) took 29.9s, 101579 effective words/s\n",
      "2019-01-08 19:42:20,198 : INFO : EPOCH 4 - PROGRESS: at 4.37% examples, 113161 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:21,253 : INFO : EPOCH 4 - PROGRESS: at 8.73% examples, 117084 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:22,319 : INFO : EPOCH 4 - PROGRESS: at 14.13% examples, 118112 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:42:23,384 : INFO : EPOCH 4 - PROGRESS: at 19.92% examples, 119157 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:24,386 : INFO : EPOCH 4 - PROGRESS: at 24.12% examples, 118565 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:25,432 : INFO : EPOCH 4 - PROGRESS: at 25.65% examples, 118673 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:26,453 : INFO : EPOCH 4 - PROGRESS: at 29.66% examples, 119677 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:27,477 : INFO : EPOCH 4 - PROGRESS: at 33.73% examples, 120038 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:42:28,505 : INFO : EPOCH 4 - PROGRESS: at 36.67% examples, 120505 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:29,540 : INFO : EPOCH 4 - PROGRESS: at 39.20% examples, 119929 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:30,547 : INFO : EPOCH 4 - PROGRESS: at 42.05% examples, 120043 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:31,592 : INFO : EPOCH 4 - PROGRESS: at 45.08% examples, 120340 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:42:32,651 : INFO : EPOCH 4 - PROGRESS: at 48.15% examples, 120735 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:33,718 : INFO : EPOCH 4 - PROGRESS: at 51.77% examples, 121059 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:42:34,746 : INFO : EPOCH 4 - PROGRESS: at 55.16% examples, 120957 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:35,760 : INFO : EPOCH 4 - PROGRESS: at 59.04% examples, 121004 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:36,795 : INFO : EPOCH 4 - PROGRESS: at 64.22% examples, 121334 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:37,839 : INFO : EPOCH 4 - PROGRESS: at 70.20% examples, 121680 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:38,859 : INFO : EPOCH 4 - PROGRESS: at 74.16% examples, 120823 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:39,930 : INFO : EPOCH 4 - PROGRESS: at 79.11% examples, 120661 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:42:40,962 : INFO : EPOCH 4 - PROGRESS: at 84.83% examples, 120624 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:42,008 : INFO : EPOCH 4 - PROGRESS: at 88.94% examples, 120191 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:43,024 : INFO : EPOCH 4 - PROGRESS: at 92.95% examples, 119918 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:44,088 : INFO : EPOCH 4 - PROGRESS: at 98.14% examples, 119840 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:44,509 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-08 19:42:44,510 : INFO : EPOCH - 4 : training on 3298438 raw words (3034132 effective words) took 25.3s, 119750 effective words/s\n",
      "2019-01-08 19:42:45,551 : INFO : EPOCH 5 - PROGRESS: at 4.37% examples, 111715 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:46,574 : INFO : EPOCH 5 - PROGRESS: at 8.45% examples, 113673 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:47,632 : INFO : EPOCH 5 - PROGRESS: at 13.10% examples, 110722 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:48,656 : INFO : EPOCH 5 - PROGRESS: at 18.01% examples, 110013 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:49,703 : INFO : EPOCH 5 - PROGRESS: at 23.26% examples, 110980 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:50,748 : INFO : EPOCH 5 - PROGRESS: at 25.37% examples, 113403 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:51,822 : INFO : EPOCH 5 - PROGRESS: at 28.57% examples, 115396 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:52,844 : INFO : EPOCH 5 - PROGRESS: at 32.85% examples, 116360 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:53,898 : INFO : EPOCH 5 - PROGRESS: at 36.09% examples, 117212 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:54,953 : INFO : EPOCH 5 - PROGRESS: at 38.95% examples, 117396 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:56,021 : INFO : EPOCH 5 - PROGRESS: at 41.55% examples, 117046 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:57,025 : INFO : EPOCH 5 - PROGRESS: at 44.22% examples, 116702 words/s, in_qsize 2, out_qsize 0\n",
      "2019-01-08 19:42:58,036 : INFO : EPOCH 5 - PROGRESS: at 46.87% examples, 117134 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:42:59,077 : INFO : EPOCH 5 - PROGRESS: at 50.74% examples, 118391 words/s, in_qsize 1, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-08 19:43:00,135 : INFO : EPOCH 5 - PROGRESS: at 54.82% examples, 119986 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:43:01,181 : INFO : EPOCH 5 - PROGRESS: at 59.16% examples, 120934 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:43:02,186 : INFO : EPOCH 5 - PROGRESS: at 65.52% examples, 122464 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:43:03,230 : INFO : EPOCH 5 - PROGRESS: at 71.95% examples, 124165 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:43:04,260 : INFO : EPOCH 5 - PROGRESS: at 78.41% examples, 125889 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:43:05,295 : INFO : EPOCH 5 - PROGRESS: at 85.55% examples, 127311 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:43:06,316 : INFO : EPOCH 5 - PROGRESS: at 90.66% examples, 127924 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:43:07,354 : INFO : EPOCH 5 - PROGRESS: at 96.51% examples, 129109 words/s, in_qsize 1, out_qsize 0\n",
      "2019-01-08 19:43:07,889 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-08 19:43:07,889 : INFO : EPOCH - 5 : training on 3298438 raw words (3033362 effective words) took 23.4s, 129759 effective words/s\n",
      "2019-01-08 19:43:07,890 : INFO : training on a 16492190 raw words (15167712 effective words) took 145.0s, 104606 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(sentences=docs, \n",
    "                         workers=num_workers,\n",
    "                         size=num_features,\n",
    "                         min_count=min_word_count,\n",
    "                         window=context,\n",
    "                         sample=downsampling\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1726717f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-08 19:43:09,113 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-08 19:43:09,931 : INFO : saving Word2Vec object under word2vec trial, separately None\n",
      "2019-01-08 19:43:09,933 : INFO : not storing attribute vectors_norm\n",
      "2019-01-08 19:43:09,935 : INFO : not storing attribute cum_table\n",
      "2019-01-08 19:43:11,648 : INFO : saved word2vec trial\n"
     ]
    }
   ],
   "source": [
    "model_name = \"word2vec trial\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('영리', 0.778386116027832),\n",
       " ('공공기관', 0.7518014907836914),\n",
       " ('민영화', 0.7491475343704224),\n",
       " ('개혁', 0.7326236367225647),\n",
       " ('방만', 0.7104096412658691),\n",
       " ('조기', 0.6907832622528076),\n",
       " ('경제민주화', 0.676612138748169),\n",
       " ('공공', 0.6713688373565674),\n",
       " ('의료', 0.6595103144645691),\n",
       " ('노동계', 0.6501958966255188),\n",
       " ('대타협', 0.6464426517486572),\n",
       " ('수서', 0.6406702995300293),\n",
       " ('수행', 0.6394824981689453),\n",
       " ('복지', 0.6383781433105469),\n",
       " ('정규직', 0.6340497732162476),\n",
       " ('증세', 0.6276401281356812),\n",
       " ('감축', 0.6250421404838562),\n",
       " ('연금', 0.6163124442100525),\n",
       " ('논의합', 0.6148614287376404),\n",
       " ('파이', 0.613141655921936),\n",
       " ('노동시장', 0.6128893494606018),\n",
       " ('기획재정부', 0.6109168529510498),\n",
       " ('낙하산', 0.6078866720199585),\n",
       " ('일자리', 0.6076011657714844),\n",
       " ('서민', 0.6061268448829651),\n",
       " ('환노위', 0.6054810881614685),\n",
       " ('김종국', 0.6030285358428955),\n",
       " ('재정', 0.600617527961731),\n",
       " ('줄이는', 0.5972890257835388),\n",
       " ('노사', 0.5970476269721985)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('공기업', topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
